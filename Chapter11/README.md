# Chapter 11
A Hybrid Cloud Hyperscale Use Case – Scaling a Kubernetes Workload
## Description

Setup steps:
1. Install Juju Client in a management host
2. Create an IAM user in an AWS Account with Programmatic Access (Access Key/Secret Access Key)
3. Setup the generated key pair in the management host by selecting the desired region ($ juju add-credentials aws)
4. Bootstrap the Juju controller in AWS ($juju bootstrap aws juju-controller)
  4.1. Note that the spawn EC2 instance in AWS with m7g.medium size (default Juju configuration). To change the instance constraints checkout https://juju.is/docs/juju/constraint
  4.2. Note the assigned public IP in the AWS console of the Juju controller EC2 instance
5. List controllers ($ juju list-controllers)
6. Check the Juju Dashboard ($ juju dashboard)
  6.1. Switch to the juju controller: ($ juju switch juju-controller)
  6.2. Deploy the Juju Dashboard Charm for K8s: ($ juju deploy juju-dashboard-k8s dashboard)
  6.3. Link to dashboard to the selected Controller ($ juju integrate dashboard juju-controller)
  6.4. Expose finally the dashboard for access ($ juju expose dashboard)
7. Deploy K8s charm to run production K8s cluster ($ juju deploy charmed-kubernetes)
  7.1. Note the deployed K8s resources: (K8s master/slave nodes, CA, etdc, K8s API LB, Container Engine, Virtual Networking - Calico) 
  7.2. Install Kubectl to start managing K8s cluster in the management host (to run in Mac/Unix)
  7.3. Forward access to management machine on port 8001 using Kubectl proxy command line on local machine ($ kubectl proxy --address='127.0.0.1' --port=8001) 
  7.4. Check on a browser: http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/

8. Add OpenStack cloud in Juju to deploy Juju Controller for K8s in OpenStack environment from the Management host ($ juju add-cloud)

9. Authenticate against the OpenStack API using existing Tenant credentials (using default admin credentials auto-generated) ($juju add-credential awesome-openstack)

Enter credential name: openstack_credential
 Using auth-type "userpass".
 Enter username: admin
 Enter password: 
 Enter tenant-name (optional): TENANT01 
 Enter tenant-id (optional): 
 Enter version (optional): 
 Enter domain-name (optional):
 Enter project-domain-name (optional): u1471Dom 
 Enter user-domain-name (optional): u1471Dom 
 Credential "openstack-credential" added locally for cloud "awesome-openstack".

 Where: 
  u1471Dom is an existing  domain defined in Openstack
  u1471Dom is an existing  project defined in Openstack

* can also use clouds.yaml file generated by kolla-ansible and run: ($juju add-credential awesome-openstack -f clouds.yaml)

Reference: https://old-docs.jujucharms.com/2.5/en/clouds-openstack#manually-adding-an-openstack-cloud

10. Boostrap the new Juju controller in OpenStack named juju-controller2 ($ juju bootstrap awesome-openstack juju-controller2)

11. Deploy the K8s cluster in OpenStack ($ juju deploy charmed-kubernetes -m juju-controller2)

12. Check the status of the cluster in Juju controller running in OpenStack ($ juju status -m juju-controller2)

  12.1. Check the status of the deployment process ($watch -c juju status )

13. Create a new directry for client interaction with the clusters in the management host ($ mkdir -p ~/.kube)

14. Both cluster management centralization:
  14.1. Switch to the AWS controller ($ juju switch aws) 
  14.2. Copy the config of AWS Charmed Kubernetes cluster to ~/.kube/config ($juju scp kubernetes-master/0:config ~/.kube/aws-config)

  14.3. Switch to the OpenStack controller ($ juju switch awesome-openstack) 
  14.4. Copy the config of OpenStack Charmed Kubernetes cluster to ~/.kube/config ($juju scp kubernetes-master/0:config ~/.kube/os-config)
    
15. Check the K8s cluster from the management host for:
  15.1. AWS K8s Cluster ($ kubectl cluster-info --kubeconfig=~/.kube/aws-config)
  15.2. OpenStack K8s Cluster ($ kubectl cluster-info --kubeconfig=~/.kube/os-config) 

16. Run K8s Federation: Create a new Federation controller  either in AWS or OpenStack clouds (Chosen option is OpenStack)
  16.1. Switch to the OpenStack controller ($ juju switch awesome-openstack)
  16.2. Deply a new K8s federation controller(named juju-controller-fed) in OpenStack using Juju charms ($ juju deploy charmed-kubernetes -m juju-controller-fed) 
  16.3. Check the status of the new cluster that runs 9 K8s components without error from the management host running Juju client ($juju status)
  16.4. Copy the config of the Federation controller under ~/.kube directory ($ juju scp kubernetes-master/0:config ~/.kube/fed-config)
  16.5. Create one config view for all K8s clusters in one single config file:
    16.5.1. Create new config file under ~/.kube directory ($ touch ~/.kube/config)
    16.5.2. Set the KUBECONFIG environment variable with a list of paths to all configuration file ($ export KUBECONFIG=~/.kube/config:~/.kube/os-config:~/.kube/aws-config: ~/.kube/fed-config)
    16.5.3. Merge the configuration using kubeconfig command line ($ kubectl config view --flatten > ~/.kube/config)
    16.5.4. Display the list of the available K8s cluster contexts ($ kubectl config get-contexts) or by running to display clusters defined in the fed-config file ($kubectl config get-clusters)

17. Configure DNS for quering federated service controller:
  17.1. Switch to the federation controller ($ juju switch juju-controller-fed)
  17.2. Enable CoreDNS as DNS provider via Juju command line ($ juju config kubernetes-master enable-coredns=True) (Learn more about https://kubernetes.io/docs/tasks/administer-cluster/coredns/)
  17.3. Create DNS config file (coredns-provider.conf) file and specify the IP address of the host running etcd service (obtained from the $juju status output of the juju-controller-fed controller ) and DNS zone:
    [Global]
    etcd-endpoints = http://10.0.0.54:2379
    zones = kube-fed.com. 
  Change zone name based on your configuration/needs 
  To install and run CoreDNS (https://coredns.io/manual/installation/)

18. Deploy the Federation control plane on the federation controller (juju-controller-fed) using Kubefed
  18.1. Download Kubefed client tool on the management host (MAC) (curl -LO https://github.com/kubernetes-sigs/kubefed/releases/download/v0.1.0-rc3/kubefedctl-0.1.0-rc3-darwin-amd64.tgz)
    For different OS platform check the Kubefedctl CLI download binary instructions : https://github.com/kubernetes-retired/kubefed/blob/master/docs/installation.md 
    18.1.1. Example: Version 0.10.0, OS: linux, ARCH: amd64, 
      Check releases https://github.com/kubernetes-retired/kubefed/releases

      VERSION=<latest-version, e.g. 0.1.0-rc3>
      OS=<darwin/linux>
      ARCH=amd64
      curl -LO https://github.com/kubernetes-sigs/kubefed/releases/download/v${VERSION}/kubefedctl-${VERSION}-${OS}-${ARCH}.tgz
      tar -zxvf kubefedctl-*.tgz
      chmod u+x kubefedctl
      sudo mv kubefedctl /usr/local/bin/ # make sure the location is in the PATH

  18.2. Extract the binaries and set permissions of the files ($tar -xzvf kubernetes-client-darwin-amd64.tar.gz ;$ sudo cp kubernetes/client/bin/kubefed /usr/local/bin; $ sudo chmod +x /usr/local/bin/kubefed )

  18.3. Initialize the federation cluster service with new federation instance (hybridfed)($ kubefed init hybridfed --host-cluster-context=juju-controller-fed --dns-provider="coredns" --dns-zone-name=" kube-fed.com"--dns-provider-config=coredns-provider.conf)

  19. Federation management and operations:
    19.1. Switch to the new K8s federated context (hybridfed)  ($ kubectl config use-context hybridfed)
    19.2. Add Kubernetes clusters running in AWS cloud to the joined Federation context ($ kubefed join aws --host-cluster-context=juju-controller-fed)
    19.3. Add Kubernetes clusters running in OpenStack cloud to the joined Federation context ($ kubefed join awesome-openstack --host-cluster-context=jujucontroller-fed)
    19.4. List federated clusters ($ kubectl get clusters)

  
  20. Test federation of K8s resources - Demo for namespaces:
    20.1. Create a simple manifest(fed-ns.yaml) for K8s namespace named (fed-ns)
      apiVersion: v1
      kind: Namespace
      metadata:
        name: fed-ns

    20.2. Apply the namespace file to be created in the Federating context 'hybridfed' ($ kubectl --context=hybridfed create –f fed-ns.yaml)
    20.3. Check the creation of the namespace in AWS context ($ kubectl --context=aws get ns)
    20.4. Check the creation of the namespace in AWS context ($ kubectl --context=awesome-openstack get ns)
    20.5. Perform more tests by deploying Pods and check them in both contexts 




## Code - How-To:

The Chapter uses the kolla-ansible community [repostority](https://github.com/openstack/kolla-ansible).

 Start by cloning the project code from Github:
```
git clone https://github.com/openstack/kolla-ansible.git
```

> [!TIP]
> Blank.


You can check the branch naming standard used by the OpenStack community in the Github page by clicking on the Switch branches/tags button the top right of the page:

![Branch Naming](IMG/Branches-Names-Standards.png)

Branches with **stable/** prefix are still maintained. Non maintained OpenStack releases are named with branches with **unmaintained/** prefix. 

> [!IMPORTANT]
> Blank


## Deployment in Local environment:

To deploy OpenStack in a Multi Node  environment, a virtual environment can be installed  with the following hardware and software pre-requesities:


Example used from production environment, can use any compute node with other capacities example :


*** HA Diagram mit IP ***


## Troubleshooting:

### Kolla Ansible

### Jenkins
Git authentification access 
jenkins user upgrade to sudoers users with NOPASSW
Add /bin/bash for the Jenkins shell configuration to execute 

### Git
Custom repo based on local or remote Git Server.. Change the ***ci.os*** git server name/IP to use your server:
```
   stage('INSTALLING Kolla Ansible') {
      steps {
        echo '--INSTALLING Kolla Ansible --'
        sh '''#!/bin/bash 
        pip install git+https://git@ci.os/git/openstack_deploy/openstack_deploy
        kolla-ansible install-deps
        ''' 
      }
    } 
```

### Local Jenkins File kolla-ansible 

Jenkins Job to copy inventory and globals.yml files from private repository. The example uses the same directory structure based on default OpenStack folder structure

```
stage('Preparing Infrastructure') {
      steps {
        echo '--Preparing Infrastructure Files Structure --'
        sh ''' #!/bin/bash 
        sudo mkdir -p /etc/kolla
        sudo chown $USER:$USER /etc/kolla
        cp -r /usrlocal/share/kolla-ansible/etc_examples/kolla/* /etc/kolla 
        cp -r /usr/local/share/kolla-ansible/ansible/inventory/* /etc/kolla 
        sed -i 's/^#kolla_base_distro:.*/kolla_base_distro: "ubuntu"/g' /etc/kolla/globals.yml
        sed -i 's/^#enable_haproxy:.*/enable_haproxy: "no"/g' /etc/kolla/globals.yml
        sed -i 's/^#network_interface:.*/network_interface: "eth0"/g' /etc/kolla/globals.yml
        sed -i 's/^#neutron_external_interface:.*/neutron_external_interface: "eth1"/g' /etc/kolla/globals.yml
        sed -i 's/^#kolla_internal_vip_address:.*/kolla_internal_vip_address: "10.0.2.15"/g' /etc/kolla/globals.yml
        ''' 
      }
    }
```