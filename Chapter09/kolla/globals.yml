---
# You can use this file to override _any_ variable throughout Kolla.
# Additional options can be found in the
# 'kolla-ansible/ansible/group_vars/all.yml' file. Default value of all the
# commented parameters are shown here, To override the default value uncomment
# the parameter and change its value.

###################
# Ansible options
###################

## Use ubuntu as base OS runtime for Kolla container images

# Valid options are ['centos', 'debian', 'rocky', 'ubuntu']
kolla_base_distro: "ubuntu"

## Use the Master default stable branch - changing the release name must be carefully checked in the local or remote remote branch
# Do not override this unless you know what you are doing.
openstack_release: "master"

# This should be a VIP, an unused IP on your network that will float between
# the hosts running keepalived for high-availability. If you want to run an
# All-In-One without haproxy and keepalived, you can set enable_haproxy to no
# in "OpenStack options" section, and set this value to the IP of your
# 'network_interface' as set in the Networking section below.

## Chapter 2
# VIP won't be used only until chapter 7, can still be assigned with IP of Cloud Controller management interface
# Mae sure to change this value once a VIP is created from Chapter 7
# kolla_internal_vip_address: "10.0.0.15"

## Chapter 7
# Update the VIP internal address as enabling HAProxy across 3 Cloud Contoller nodes
 kolla_internal_vip_address: "10.0.0.47"

# This should be a VIP, an unused IP on your network that will float between
# the hosts running keepalived for high-availability. It defaults to the
# kolla_internal_vip_address, allowing internal and external communication to
# share the same address.  Specify a kolla_external_vip_address to separate
# internal and external requests between two VIPs.

## Chapter 7
# Keep the default optionally to use the kolla_internal_vip_address (in this example "10.0.0.47")
kolla_external_vip_address: "{{ kolla_internal_vip_address }}"


########################
# Nova - Compute Options
########################
## Make sure the selected hypervisor in the host is installed properly 

# Valid options are [ qemu, kvm, vmware ]
nova_compute_virt_type: "kvm"


##############################
# Neutron - Networking Options
##############################
# This interface is what all your api services will be bound to by default.
# Additionally, all vxlan/tunnel and storage network traffic will go over this
# interface by default. This interface must contain an IP address.
# It is possible for hosts to have non-matching names of interfaces - these can
# be set in an inventory file per host or per group or stored separately, see
#     http://docs.ansible.com/ansible/latest/intro_inventory.html
# Yet another way to workaround the naming problem is to create a bond for the
# interface on all hosts and give the bond name here. Similar strategy can be
# followed for other types of interfaces.

## Make sure to enter the actual name of network interface shown in your Operating System
network_interface: "eth0"

# This is the raw interface given to neutron as its external network port. Even
# though an IP address can exist on this interface, it will be unusable in most
# configurations. It is recommended this interface not be configured with any IP
# addresses for that reason.

## Make sure to enter the actual name of network interface shown in your Operating System
## Chapter 6: Configuring OVN
neutron_external_interface: "eth2"

# Valid options are [ openvswitch, ovn, linuxbridge, vmware_nsxv, vmware_nsxv3, vmware_nsxp, vmware_dvs ]
# if vmware_nsxv3 or vmware_nsxp is selected, enable_openvswitch MUST be set to "no" (default is yes)
# Do note linuxbridge is *EXPERIMENTAL* in Neutron since Zed and it requires extra tweaks to config to be usable.
# For details, see: https://docs.openstack.org/neutron/latest/admin/config-experimental-framework.html


########### OVS  ############# 
## Chapter 6
# Using OpenvSwitch plugin for Neutron networking
neutron_plugin_agent: "openvswitch"


############ OVN ############ 

# Using OVN as Neutron plugin agent
#neutron_plugin_agent: "ovn"

# Enable distributed floating IP
#neutron_ovn_distributed_fip: "yes"

# Enable QoS OVN agent for Neutron
#neutron_enable_ovn_agent: "yes"

###################
# OpenStack options
###################

## Enable Neutron provider network for external access
enable_neutron_provider_networks: "yes"

#### Chapter04:  Enable Magnum Service
enable_magnum: "yes"

### Chapter04: Enable Zun service with Docker for container management and Kuryr for container networking 
enable_zun: "yes"
enable_kuryr: "yes"
enable_etcd: "yes"
docker_configure_for_zun: "yes"
containerd_configure_for_zun: "yes"

### Chapter05: Use LVM as storage backend for Cinder service as created using pvcreate and vgcreate command lines in storage node: cinder-volumes
enable_cinder_backend_lvm: "yes"
cinder_volume_group: "cinder-volumes"

### Chapter05: Use NFS as storage backend for Cinder service as created using nfs-common command lines in storage node path: /nfs/share/cinder
enable_cinder_backend_nfs: "yes"

### Chapter05: Use CEPH as storage backend for Cinder service as created using rbd command lines in storage node pool: cinder-volumes
cinder_backend_ceph: "yes"
ceph_cinder_keyring: "ceph.client.cinder.keyring"
ceph_cinder_user: "cinder"
ceph_cinder_pool_name: "cinder-volumes"

### Chapter05: Use and integrate Swift for object storage in the running OpenStack environment (3 Nodes)
enable_swift : "yes"

### Chapter05: Enable Manila file-share service using a generic Cinder storage backend 
enable_manila : "yes"
enable_manila_backend_generic: "yes"

### Chapter06: Enable BGP Agent installation 
#enable_neutron_bgp_dragent: "yes"

### Chapter06: Enable Octavia  installation and assign network interface to communicate with the service through Management network
enable_octavia: "yes"
octavia_network_interface: eth0
# Optionally auto configure Octavia 
# octavia_auto_configure: "yes"

### Chapter07: Enable HAProxy as part of dedicatd Load Balancing servers farm
# Make sure two HAProxy nodes and three Cloud Controller nodes are already in place in the inventory file 
enable_haproxy: "yes"
kolla_external_vip_address: "10.0.0.47"

# Enable HA for Neutron L3 agent after adding second Network Node 
enable_neutron_agent_ha: "yes"

# Enable DVR routing capability in Neutron
enable_neutron_dvr: "yes"

### Chapter07: Enable Masakari for instance failover
enable_masakari: "yes"
# Enable HA for instances evacuation during instance failure events
enable_hacluster: "yes"

### Chapter08: 
## Enable Prometheus for Monitoring
enable_prometheus: "yes"
## Enable Grafana for metrics visualization 
enable_grafana: "yes"
## Optionally extend the Promotheus default commands by setting custom configurations when Prometheus starts.
## The following example sets limits on maximum number of simultaneous connections, log level, frequency of alerts reporting and retention period of metrics data in storage:
prometheus_cmdline_extras: " --web.max-connections 30 --log.level error --rules.alert.resend-delay 30s --storage.tsdb.retention.time 30d "  

### Chapter08: 
## Enable Ceilometer for OpenStack Telemetry
enable_ceilometer: "yes"
## Enable Gnocchi with Statsd for OpenStack Telemetry data store
enable_gnocchi: "yes"
enable_gnocchi_statsd: "yes"
## Enable Aodh for OpenStack Telemetry alerting
enable_aodh: "yes"

## Enable Central logging for OpenSearch 
enable_central_logging: "yes"

### Chapter09:
## Enable Memcached service and for all nodes running behing the load balancer
enable_memcached: "yes"
enable_haproxy_memcached: "yes"

### Chapter09:
## Enable OSProfiler for OpenStack service tracing
enable_memcached: "yes"
## Enable ElasticSearch as backend store for OSProfiler data instead of default Redis
enable_elasticsearch: "yes"

## Enable Watcher for resources optimization service
enable_watcher: "yes"

################################
# Swift - Object Storage Options
################################

## # This parameter defines matching pattern: if "strict" mode was selected,
# for swift_devices_match_mode then swift_device_name should specify the name of
# the special swift partition for example: "KOLLA_SWIFT_DATA", if "prefix" mode was
# selected then swift_devices_name should specify a pattern which would match to
# filesystems' labels prepared for swift.

## Default is 'strict' mode. 
# swift_devices_name: "KOLLA_SWIFT_DATA"

## If you have labeled hard disks with eg objdisk1, objdisk2, objdisk3, use the following settings: 
## swift_devices_match_mode: "prefix"
## swift_devices_name: "objdisk" 



################
# Docker options
################

## Use local or remote  Custom docker registry as demonstrated in Chapter 2: Kicking Off the OpenStack Setup â€“ The Right Way (DevSecOps)
docker_registry: 10.0.0.15:4000

## Not recommended configuration. The option will allow to use pull/push Docker images without a Certificate Authority. Make sure to install a TLS certificate to reach the Docker registry in production environments. The option is set to false for the sake of demonstration.
## More information can be found at https://docs.docker.com/registry/
docker_registry_insecure: "yes"






